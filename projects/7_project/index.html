<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Modifying MinBERT | Kabir Jolly</title> <meta name="author" content="Kabir Jolly"> <meta name="description" content="CS 224N Final Project"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%B2&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://kabir-jolly.github.io/projects/7_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Kabir </span>Jolly</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/experience/">experience</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Modifying MinBERT</h1> <p class="post-description">CS 224N Final Project</p> </header> <article> <p><a href="https://web.stanford.edu/class/cs224n/" rel="external nofollow noopener" target="_blank">CS 224N (Natural Language Processing with Deep Learning)</a> was a wonderful class I took during the winter quarter of my junior year. Prior to taking 224N, I had already taken a bunch of other AI/ML/DL classes and this one is known to be one of the more approachable courses to begin with, so I did not find the class to be too challenging at all. It was extremely well taught and I really appreciated how the course staff modified much of the material to remain fairly topical (side note: this definitely one of Stanford’s greatest strengths as an academic institution). Much of the final portion of the class was entirely devoted to covering the cutting-edge (especially with ChatGPT released only a few months prior to this offering) - a large reason why this class had over 650 students enrolled.</p> <p>While I cannot share the code for this project given Stanford’s Honor Code, I would love to share the work that went into the final project conducted by Govind Chada and myself. If you would prefer to read the whole paper, you can find it <a href="/assets/pdf/224N_final_report.pdf">here</a>.</p> <h4> Background </h4> <p>BERT, or Bidirectional Encoder Representations from Transformers, is an LLM based on the transformer architecture.</p> <ul> <li>Especially powerful when it comes to sequential textual data</li> <li>Training pipeline consists of pre-training on a large body of text and then fine-tuning it for a particular NLP task</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/224n/224n1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="overview" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>In many domains such as healthcare and education, data collection is challenging, and training LLMs to perform well in these fields benefits from bootstrapping the performance on a specific task by utilizing learnings from other tasks where far more data is easily accessible.</p> <h4> Problem </h4> <p>BERT has been shown to perform well on a variety of natural language tasks. However, these models are optimized during training to perform well on a particular task. This inspires the central question that motivates this work: How can we perform multiple tasks with high accuracy?</p> <p>For this project, we adapt BERT to solve 3 main tasks:</p> <ol> <li>Sentiment Analysis <ul> <li>Stanford Sentiment Treebank dataset</li> <li>Phrases assigned labels of negative, somewhat negative, neutral, somewhat positive, or positive (0-4 respectively)</li> </ul> </li> <li>Paraphrase Detection <ul> <li>Quora dataset</li> <li>Binary labels describing whether a pair of questions are paraphrases of each other</li> </ul> </li> <li>Semantic Textual Similarity <ul> <li>SemEval STS Benchmark dataset</li> <li>Label measures degree of similarity between a pair of sentences (on a scale from 0 to 5, where 0 means unrelated and 5 means the pair has the same meaning)</li> </ul> </li> </ol> <h4> Methodology and Results </h4> <h5> Phase 1: Baseline, Gradient Surgery, and Cosine Similarity </h5> <p>Baseline approach: BERT model with separate head for each task. Different loss functions used for each head.</p> <ol> <li>Sentiment analysis: Cross Entropy Loss</li> <li>Paraphrase detection: Binary Cross Entropy Loss</li> <li>Semantic textual similarity: Mean Squared Error</li> </ol> <p>Experimentation to expand upon the baseline included:</p> <ol> <li>Naïve gradient surgery (worse performance)</li> <li>Cosine similarity (CS) (significant improvement)</li> <li>CS with gradient surgery (GS) to counteract conflicting gradients (even more improvement)</li> <li>CS + GS and no dropout (best model during Phase 1)</li> </ol> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/224n/224n2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="phase1_arch" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h5> Phase 2: Training Pipeline Modifications </h5> <p>We then modified the approach taken in Phase 1 through a 3-step process</p> <ul> <li>Pre-train using 3 separate BERT models, one for each task</li> <li>Average outputs to be used as a stronger initialization for multitask finetuning</li> </ul> <p>This methodology was coupled with the trials that were already shown to perform the best in Phase 1, namely cosine similarity and gradient surgery, with and without dropout.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/224n/224n3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="phase2_training" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/224n/224n4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="results" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h4> Analysis </h4> <p>We found the best performing model consists of our training method in combination with gradient surgery and cosine similarity</p> <ul> <li>Naively applying gradient surgery negatively impacts results due to strongly conflicting gradients between the tasks</li> <li>Cosine similarity brings the tasks more in line with each other and allows for better multitask model performance</li> <li>This also constrains the output of the head to be between 0 and 5, rather than letting the model learn this</li> <li>Using both gradient surgery and cosine similarity together boosts overall performance across the tasks, and combining this with our training scheme allows for even greater performance</li> <li>This shows the importance of a good initialization point to begin finetuning from and an even more efficient pretraining process could probably improve the results further</li> <li>We also found that the model begins to overfit after only a few epochs of finetuning but, removing dropout led to improved performance on the dev data</li> </ul> <h4> Conclusion </h4> <p>Throughout the course of this project, we were able to empirically determine certain modifications to our baseline multitask BERT implementation that resulted in stronger task-specific and overall performance. Our best model used single task pretraining to provide a strong initialization for multitask finetuning, combined with CS, GS and removing dropout regularization. While experimental success was logged using the dev datasets, our overall test score was found to be 0.702.</p> <p>Limitations include:</p> <ul> <li>Universally low performance on the sentiment classification task, pulling down the overall score greatly</li> <li>Cosine similarity only benefitted the STS task, and we did not find any beneficial task-specific approaches for the Para and SST tasks</li> </ul> <p>One future step in involves trying an optimization based meta-learning approach such as MAML. We saw having a good initialization point before finetuning improved downstream task performance, so with the construction of more related tasks for meta-training, we hypothesize this may boost performance across the board.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Kabir Jolly. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: July 21, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>